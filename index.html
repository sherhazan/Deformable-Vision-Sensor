<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A robust learning-based 3D vision sensor designed for estimating the relative position between both rigid and deformable objects in real-time using Late Fusion CNN.">
  <meta name="keywords" content="Robotic Assembly, Peg-in-Hole, Deformable Objects, Computer Vision, Late Fusion, RGB-D">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning-Based 3D Vision Sensor for Robotic Peg-In-Hole Insertion of Deformable Objects</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg">  -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Learning-Based 3D Vision Sensor for Robotic Peg-In-Hole Insertion of Deformable Objects</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Sher Hazan,</span>
            <span class="author-block">Eylon Cohen,</span>
            <span class="author-block">Ronit Schneor,</span>
            <span class="author-block">Anath Fischer,</span>
            <span class="author-block">Miriam Zacksenhouse</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Technion - Israel Institute of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://sherhazan.github.io/Deformable-Vision-Sensor/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/YOUR_ARXIV_ID"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/sherhazan/LDO-robotic-insertion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Real-time robotic control using our 3D Vision Sensor. The system robustly estimates the relative position of the deformable medical pipe to ensure successful insertion.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The integration of precise object positioning systems in robotic assembly tasks, particularly Peg-in-Hole (PIH) operations, is crucial for enhancing automation efficiency in industrial environments. The challenge intensifies when dealing with deformable objects. Advanced sensors and learning methods are recruited to face such challenges. This research presents a robust learning-based 3D vision sensor which is designed for estimating the relative position between both rigid and deformable objects in real-time. It is planned to be embedded into a robotic PIH insertion pipeline in the industrial environment. Our 3D vision sensor incorporates capturing the 3D scene, predicting a probability vector indicating the relative position between the peg and hole. It uses a late fusion convolutional neural network (CNN) architecture for classification, extracting the continuous relative position from the probabilities vector. The estimated relative position is then utilized to refine the pegâ€™s position during the insertion process. The efficiency of the 3D vision sensor was evaluated across various PIH tasks involving both rigid and deformable objects. Moreover, it was embedded into an industrial robotic cell without additional training in order to validate its robustness and generalization capabilities. The approach demonstrated high success rate, highlighting its effectiveness and applicability in real-world industrial settings.
          </p>
        </div>
      </div>
    </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Methodology</h2>
        <div class="content has-text-justified">
          <p>
            Our solution moves away from direct regression, which often struggles with the high variability of deformable objects. Instead, we employ a novel <strong>Classification-to-Regression</strong> approach:
          </p>
          <ul>
            <li><strong>Input:</strong> The system takes centered RGB images and Depth maps as input.</li>
            <li><strong>Late Fusion Backbone:</strong> Two separate ResNet-18 streams extract features from RGB and Depth independently. These features are concatenated only at the fully connected layer.</li>
            <li><strong>Discretization:</strong> The continuous space (Radius and Angle) is divided into discrete classes.</li>
            <li><strong>Interpolation Logic:</strong> We recover the continuous value using a weighted mean of the predicted probability vector. For angles, we utilize circular mean calculation to handle periodicity.</li>
          </ul>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Experimental Results</h2>
        
        <div class="content has-text-justified">
          <p>
            The system was evaluated on both rigid and deformable insertion tasks, including classic peg-in-hole and flexible medical tube assembly. The proposed vision sensor significantly outperformed standard force-based baselines.
          </p>
        </div>

        <div class="content has-text-centered">
          <table class="table is-striped is-bordered is-hoverable" style="margin-left: auto; margin-right: auto;">
            <thead>
              <tr>
                <th>Task</th>
                <th>Baseline Success Rate</th>
                <th>Ours (Vision Sensor)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Classical PIH (4.5mm)</td>
                <td>83%</td>
                <td><strong>100%</strong></td>
              </tr>
              <tr>
                <td>Large Peg (16mm)</td>
                <td>51%</td>
                <td><strong>90%</strong></td>
              </tr>
              <tr>
                <td>Medical Pipe (Deformable)</td>
                <td>80%</td>
                <td><strong>98%</strong></td>
              </tr>
            </tbody>
          </table>
        </div>

        <div class="columns is-centered">
          <div class="column is-half has-text-centered">
            <p><strong>Spatial Error Analysis</strong></p>
            <img src="./static/images/spatial_error_angle.png" alt="Spatial Error Graph" style="width: 100%; border: 1px solid #ddd; border-radius: 5px;">
          </div>
          <div class="column is-half has-text-centered">
             <p><strong>Regression Performance</strong></p>
            <img src="./static/images/angle_regression.png" alt="Regression Plot" style="width: 100%; border: 1px solid #ddd; border-radius: 5px;">
          </div>
        </div>

      </div>
    </div>
    </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hazan2024learning,
  title={Learning-Based 3D Vision Sensor for Robotic Peg-In-Hole Insertion of Deformable Objects},
  author={Hazan, Sher and Cohen, Eylon and Schneor, Ronit and Fischer, Anath and Zacksenhouse, Miriam},
  journal={IEEE},
  year={2024}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            Template borrowed from <a href="https://nerfies.github.io/">NeRFies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>